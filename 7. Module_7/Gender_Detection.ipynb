{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYwBRN7hUepS",
        "colab_type": "text"
      },
      "source": [
        "#**Gender Detection Using OpenCV**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMLL2Re9htVb",
        "colab_type": "text"
      },
      "source": [
        "This is a [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) notebook file. Python programs are run directly in the browserâ€”a great way to learn and use TensorFlow. To follow this tutorial, run the notebook in Google Colab by clicking the button at the top of this page.\n",
        "\n",
        "1. In Colab, connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*.\n",
        "2. Run all the notebook code cells: Select *Runtime* > *Run all*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nnsxke9Eh4Pj",
        "colab_type": "text"
      },
      "source": [
        "##**Problem Statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI0fQw8zSEku",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The **Adience** dataset includes a collection of Images & is intended to be as accurate as possible to the challenges of real-world imaging conditions. \n",
        "\n",
        "This data set was used in the paper Age and Gender Estimation of Unfiltered Faces. The paper describes the process of collecting the data set and provides additional information on the test protocols used with it.\n",
        "\n",
        "In this demo, your goal is to predict the **Gender** of a person in Real-time using OpenCV."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQLLSzt4prhE",
        "colab_type": "text"
      },
      "source": [
        "##**Tasks to be Performed**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvW6B9rapy_u",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial you will be performing the following tasks:\n",
        "- Import Required Libraries\n",
        "- Image Pre-processing\n",
        "- Implement the Pre-trained Models\n",
        "- Predict the Gender in Real-time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3v53b-Oqr-b",
        "colab_type": "text"
      },
      "source": [
        "##**Dataset Description**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFK91BYlrf-3",
        "colab_type": "text"
      },
      "source": [
        "For this python project, we are going to use the **Adience** dataset.\n",
        "This dataset serves as a benchmark for face photos and includes various real-world imaging conditions like noise, lighting, pose, and appearance. The sources of the images included in our set are Flickr albums, assembled by automatic upload from iPhone5 (or later) smart-phone devices, and released by their authors to the general public under the Creative Commons (CC) license.\n",
        "\n",
        "\n",
        "It has a total of **26,580** photos of 2,284 subjects and is about 1GB in size. \n",
        "The models that we are going to use are trained on this dataset.\n",
        "\n",
        "If you want to download the Dataset, [Click Here](https://www.kaggle.com/ttungl/adience-benchmark-gender-and-age-classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iMcGoGavTpt",
        "colab_type": "text"
      },
      "source": [
        "##**Skills Gained**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InSeMIvFScja",
        "colab_type": "text"
      },
      "source": [
        "- OpenCV\n",
        "- Deep Neural Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSf8yH-VjUSH",
        "colab_type": "text"
      },
      "source": [
        "##**Import Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBX98JkjWjPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please run the following code cells in your local system or Jupyter Notebook as Colab won't be able to access your PC's Webcam\n",
        "\n",
        "import cv2 # Impoorting OpenCV Library\n",
        "import math\n",
        "import argparse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HREIdXt6cKFN",
        "colab_type": "text"
      },
      "source": [
        "##**Image Pre-processing using OpenCV's Deep Neural Network Module**\n",
        "\n",
        "OpenCV provides two functions under the Deep Neural Network Module to facilitate Image Pre-processing for Deep Learning Classification.\n",
        "\n",
        "- cv2.dnn.blobFromImage\n",
        "- cv2.dnn.blobFromImages\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEiiBsFDUJcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def highlightFace(net, frame, conf_threshold=0.7):\n",
        "    frameOpencvDnn=frame.copy()\n",
        "    frameHeight=frameOpencvDnn.shape[0]\n",
        "    frameWidth=frameOpencvDnn.shape[1]\n",
        "    blob=cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False) \n",
        "    \n",
        "    # [blobFromImage] creates 4-dimensional blob from image. \n",
        "    # Optionally resizes and crops image from center, subtract mean values, scales values by scalefactor, swap Blue and Red channels.\n",
        "\n",
        "\n",
        "    # set the input to the pre-trained deep learning network and obtain the output predicted probabilities \n",
        "\n",
        "    net.setInput(blob) #Passing the blob through the network \n",
        "    detections=net.forward() #Grabbing the Detections/Predictions\n",
        "    faceBoxes=[]\n",
        "\n",
        "    # Filter out weak detections by ensuring the confidence is greater than the minimum confidence\n",
        "    for i in range(detections.shape[2]):\n",
        "        confidence=detections[0,0,i,2]\n",
        "        if confidence>conf_threshold:\n",
        "            x1=int(detections[0,0,i,3]*frameWidth)\n",
        "            y1=int(detections[0,0,i,4]*frameHeight)\n",
        "            x2=int(detections[0,0,i,5]*frameWidth)\n",
        "            y2=int(detections[0,0,i,6]*frameHeight)\n",
        "\n",
        "            faceBoxes.append([x1,y1,x2,y2]) #Bounding Box Co-ordinates\n",
        "\n",
        "            cv2.rectangle(frameOpencvDnn, (x1,y1), (x2,y2), (0,255,0), int(round(frameHeight/150)), 8)\n",
        "    return frameOpencvDnn,faceBoxes\n",
        "\n",
        "    #cv2.dnn.blobFromImage function returns a blob which is the input image after mean subtraction, normalizing, and channel swapping."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKdW4odGde7U",
        "colab_type": "text"
      },
      "source": [
        "If you want to learn more about OpenCV's **Deep Neural Network Module** [Click Here](https://docs.opencv.org/trunk/d6/d0f/group__dnn.html#ga33d1b39b53a891e98a654fdeabba22eb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNz4M7URZ-lz",
        "colab_type": "text"
      },
      "source": [
        "##**Implement the DNN based Pre-trained Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAR9X2CaZ9vZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser=argparse.ArgumentParser()\n",
        "parser.add_argument('--image')\n",
        "\n",
        "args=parser.parse_args()\n",
        "\n",
        "# The following two files are protobuf file (protocol buffer).\n",
        "# They contains the graph definition and the trained weights of the model. \n",
        "# A .pb file contains the protobuf file in binary format, the .pbtxt extension contains it in text format. \n",
        "\n",
        "faceProto=\"opencv_face_detector.pbtxt\"\n",
        "faceModel=\"opencv_face_detector_uint8.pb\"\n",
        "\n",
        "genderProto=\"gender_deploy.prototxt\" # Describes the Network Configuration\n",
        "genderModel=\"gender_net.caffemodel\" # Defines the Internal States of the parameters of the Layers\n",
        "\n",
        "MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746) #Initializing the Mean Values for the Model\n",
        "genderList=['Male','Female']\n",
        "\n",
        "#readNet() method is used to load the Networks\n",
        "\n",
        "#First parameter contains Trained Weights\n",
        "#Second parameter contains Network Configuration\n",
        "\n",
        "faceNet=cv2.dnn.readNet(faceModel,faceProto) \n",
        "genderNet=cv2.dnn.readNet(genderModel,genderProto)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-eZxUsCZzUf",
        "colab_type": "text"
      },
      "source": [
        "##**Capture the Video in Real-time & predict the Gender**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9mITOu7ZyGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video=cv2.VideoCapture(args.image if args.image else 0)\n",
        "padding=20\n",
        "\n",
        "while cv2.waitKey(1)<0:\n",
        "    hasFrame,frame=video.read()\n",
        "    if not hasFrame:\n",
        "        cv2.waitKey()\n",
        "        break\n",
        "\n",
        "    resultImg,faceBoxes=highlightFace(faceNet,frame)\n",
        "    if not faceBoxes:\n",
        "        print()\n",
        "\n",
        "    for faceBox in faceBoxes:\n",
        "        face=frame[max(0,faceBox[1]-padding):\n",
        "                   min(faceBox[3]+padding,frame.shape[0]-1),max(0,faceBox[0]-padding)\n",
        "                   :min(faceBox[2]+padding, frame.shape[1]-1)]\n",
        "\n",
        "        blob=cv2.dnn.blobFromImage(face, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False) \n",
        "        #returns a blob which is the input image after mean subtraction, normalizing, and channel swapping.\n",
        "        \n",
        "\n",
        "        # Making predictions on the Gender and find the Gender bucket with the largest corresponding probability\n",
        "\n",
        "        genderNet.setInput(blob) #Passing the blob through the Neural Net\n",
        "        genderPreds=genderNet.forward() #Grabbing the Detections/Predictions\n",
        "        gender=genderList[genderPreds[0].argmax()] #Displaying the Top Prediction\n",
        "        #print(f'Gender: {gender}')\n",
        "\n",
        "        cv2.putText(resultImg, f'{gender}', (faceBox[0], faceBox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2, cv2.LINE_AA)\n",
        "        #The function putText renders the specified text string in the image.\n",
        "        \n",
        "        #If you want to learn more about OpenCV Drawing Functions visit - https://docs.opencv.org/2.4/modules/core/doc/drawing_functions.html\n",
        "        \n",
        "        cv2.imshow(\"Gender Detection\", resultImg) #Display the Image in an OpenCV Window\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}